# -*- coding: utf-8 -*-
"""

Created on Sun Dec 19 22:55:32 2021

@author: Youngbin Moon (y.moon@unibas.ch)
"""

import pysam
import argparse
import os
from collections import Counter
import csv
import matplotlib.pyplot as plt
import numpy as np

"""
Aim1 : Count the number of polyA sites in a given sample and save it in csv file.

1) Get clusters of reads by a single linkage clustering 
2) Count the number of representative reads per cluster
3) Count the number of clusters that have more than 1 representative read.

This will be your number of polyA sites.

Aim2: get a distribution of how many PolyA sites/gene and draw bar plot.
"""

def get_mean(scores_list):
    """
    Parameters
    ----------
    scores_list : list of float
        A list that contains log10 'absolute' distances between end of a read and end of terminal exon.
        
    Returns
    -------
    mean_val : float
        mean value of log10 'absolute' distances between end of a read and end of terminal exon.    
    """
    mean_val = np.mean(scores_list)         
    return mean_val

def plot_histogram(GX_pas, file):
    """
    Parameters
    ----------
    GX_pas : counter object
        key : GX tag
        value : how many polyA sites per given GX tag
        
    file : string
        output histogram file name
           
    Returns
    -------
    returns nothing but plots a histogram that shows 
    a distribution of the number of polyA sites per gene.
    """
    plt.figure()
    plt.xticks(fontsize='x-large')
    plt.yticks(fontsize='x-large')
    plt.xlabel('number of poly A sites per gene', fontsize = 'x-large')
    plt.ylabel('frequency', fontsize = 'x-large')
    
    distribution = list(GX_pas.values())
    print("distribution: " + str(distribution))
    bins = np.arange(min(distribution), max(distribution), 1)
                     
    plt.hist(distribution, bins = bins, histtype='bar') 
    
    mean = get_mean(distribution)
    
    plt.rcParams['font.family'] = "Arial"
            
    title = 'mean number of polyA sites per gene: ' + str(mean) 
    plt.title(label = title, fontsize = 'x-large')
    plt.yscale("log") 
    
    plt.savefig(file, bbox_inches='tight')
    
def write_out(row_data, o_file):
    """
    Parameters
    ----------
    row_data : list
        
            
    o_file : string
        output file name    
       
    Returns
    -------        
    returns nothing but writes row_data at the csv file with output name: o_file.
    """        
    w = csv.writer(open(o_file, "w"))
    w.writerow(row_data)

def get_num_polyA_alter(dictionary, k):
    """
    Parameters
    ----------    
    dictionary : dictionary of list.
            key : a tuple of chromID, cluster_ID and direction.
            value : a list of tuple in which:
                1st element : ID (read_id + GX tags) or (read_id)
                2nd element : all "potential" cleavage sites 
                with same chromID, cluster_ID and direction.
                
                In other words, we make clusters of potential cleavage sites. 
                This dictionary has all potential cleavage sites in a specific sample.
            
            In this function,
            the most frequent read end (most frequent potential cleavage sites) 
            will be selected as a fixed "true"/"representative" cleavage site.
    
    k : int
        a threshold of how many reads should at least support this cluster in order to consider this cluster as a polyA sites.
        
    Returns
    -------
    num_polyA : int
        The number of polyA sites. We compute this by the number of clusters generated by single linkage clustering.
    
    GX_PAS_counter : counter object
        key : GX tag
        value : how many polyA sites per given GX tag
    """        
    num_polyA = 0
    GX_PAS_counter = Counter()
    # key = (chromID, cluster_ID, direction)
    # value = fixed cleavage sites    
    # elem is a cluster.
    for elem in dictionary.keys():
        # ID_read_ends_tuple = [(ID1, 181), (ID2, 185)......]
        ID_read_end_tuples = dictionary[elem]
        
        # each element = read_id + '-' + 'ENSMUSG00000022995.6;ENSMUSG00000025779.6'
        # or each element = read_id
        Ids = [elem[0] for elem in ID_read_end_tuples]
        
        # read_ends = [181, 185, 185, 190, 190, 190, 190, 190, 190......]
        read_ends = [elem[1] for elem in ID_read_end_tuples]
        
        # Counter(read_ends) = {181:1, 185:2, 190:6}
        # read_ends_keys = [181, 185, 190]       
        read_ends_keys = list(Counter(read_ends).keys())
        # read_ends_values = [1, 2, 6]
        read_ends_values = list(Counter(read_ends).values())
        # representative_read_idx = 2        
        representative_read_idx = read_ends_values.index(max(read_ends_values))
        # representative_read_end = 190
        representative_read_end = read_ends_keys[representative_read_idx]
        
        # find one of the Ids of the representative read (but GX tag should be identical amongst representative reads)
        idx = read_ends.index(representative_read_end)
        # representative_read_ID = [read_id, 'ENSMUSG00000022995.6;ENSMUSG00000025779.6'] or [read_id]
        representative_read_ID = Ids[idx].split("-")

        # Assuming all reads in a single cluster are actually representative read.
        num_representative_reads = sum(read_ends_values)
        if num_representative_reads >= k:
            num_polyA += 1
            
            # representative_read_ID = [read_id, 'ENSMUSG00000022995.6;ENSMUSG00000025779.6'] or [read_id]
            if len(representative_read_ID) == 2:
                # GX_tags = ['ENSMUSG00000022995.6', 'ENSMUSG00000025779.6']
                GX_tags = representative_read_ID[1].split(";")
                num_GX = len(GX_tags)
                
                for GX_tag in GX_tags:

                    # corrected_GX_tag = 'ENSMUSG00000022995'
                    # normalize it if there are more than 1 GX tags.
                    corrected_GX_tag = GX_tag.split(".")[0]
                    GX_PAS_counter[corrected_GX_tag] += 1/num_GX
                    
    return num_polyA, GX_PAS_counter
        
def make_cluster(tempfile):
    """
    Parameters
    ----------    
    tempfile : string
        output directory of the single linkage clustering script.
        This file contains a dataframe which has a set of clusters of reads 
        generated according to distance parameter.
        e.g. ../numPolyA_slc_output_.txt
        
    Returns
    -------
    clusters_reads_ends : dictionary of list.
            key : a tuple of chromID, cluster_ID and direction.
            value : a list of tuple in which:
                1st element : ID (read_id + GX tags) or (read_id)
                2nd element : all "potential" cleavage sites 
                with same chromID, cluster_ID and direction.
                
                In other words, we make clusters of potential cleavage sites. 
                This dictionary has all potential cleavage sites in a specific sample.
            
            In the "get_num_polyA_alter" function,
            the most frequent read end (most frequent potential cleavage sites) 
            will be selected as a fixed "true"/"representative" cleavage site.
    """        
    clusters_read_ends = {}
    with open(tempfile, "r") as t:
        for line in t:
            # clusterID is always encountered first within each cluster
            if len(line.split())==4:
                cluster_ID = line.split()[1]
            if len(line.split())==6:
                ID = line.split()[0]
                chromID = line.split()[1]
                direction = line.split()[2]
                read_start = line.split()[3]
                read_end = line.split()[4]
                
                # fixed cleavage site already considers the direction
                # read_start = fixed_cleavage_site - 1
                # read_end = fixed_cleavage_site
                cleavage_site = read_end
                    
                # add read end to the appropriate cluster
                if (chromID, cluster_ID, direction) not in clusters_read_ends.keys():
                    clusters_read_ends[(chromID, cluster_ID, direction)] = []
                clusters_read_ends[(chromID, cluster_ID, direction)].append((ID, cleavage_site))
    
    return clusters_read_ends

def write_temp (tempfile, out_put):
    """
    Parameters
    ----------    
    tempfile : string
        output directory of the single linkage clustering script.
        e.g. ../numPolyA_slc_output_.txt

    out_put : dataframe
        A dataframe that contains the output of the single linkage clustering.
        This dataframe has a set of clusters of reads generated according to distance parameter.
        
    Returns
    -------
    returns nothing but writes the out_put(output of single linkage clustering) in tempfile.
    """        
    with open(tempfile, "a+") as t:
        t.writelines(str(out_put))  

def convert_dict(list_of_tuples):
    """
    Parameters
    ----------
    list_of_tuples : a list of tuples
        an object that contains infomation about 1 read from BAM file.
        1st element of a tuple: tag name. For example, 'GX' tag
        2nd element of a tuple: value of the tag. if it is 'GX' tag,
        then value is gene name(s) that a read maps to. For example, ENSMUSG00000022995.
        
    Returns
    -------
    tag_dict : dictionary
        key = tag name. e.g. 'GX' tag.
        value = value that the tag has. e.g. if key is 'GX', value is gene name.
    """
    tag_dict = dict()
    for key, tag in list_of_tuples:
        tag_dict.setdefault(key, []).append(tag)
    return tag_dict
        
def make_input_slc(in_template, sam, distance_param):
    """
    Parameters
    ----------    
    in_template : string
        input directory template of the single linkage clustering script. 
        e.g. ../numPolyA_inputSLC_"
        
    sam : bam file
        A bam file containing all polyA reads of a specific sample.
        
    distance_param : character. e.g. '4'
        distance parameter of a single linkage clustering.
        
    Returns
    -------
    output : dataframe
        A dataframe that contains the output of the single linkage clustering.
        This dataframe has a set of clusters of reads generated according to distance parameter.
    """     
    # input directory for single linkage clustering
    input_dir = in_template + ".txt"
    with open(input_dir, "a+") as t:
        for read in sam.fetch():
            rev = read.is_reverse
            chrom = read.reference_name
            
            if rev == True:
                rev = '-'
                
            else:
                rev = '+'
                
            list_tuples = read.tags
            tag_dict = convert_dict(list_tuples)
            
            if 'GX' in tag_dict.keys():
                # GX_tags is a list of tags
                # GX_tags = ['ENSMUSG00000022995.6;ENSMUSG00000025779.6']
                GX_tags = tag_dict['GX']
                # GX_tags = 'ENSMUSG00000022995.6;ENSMUSG00000025779.6'    
                GX_tags = GX_tags[0]
                Id = read.query_name + "-" + GX_tags
                
            else:
                Id = read.query_name
            
            start = int(read.get_tag('FC')) -1
            end = int(read.get_tag('FC'))
            count = read.mapping_quality
            
            print('used fixed cleavage site')
            t.writelines(Id + " " + chrom + " " + rev + " " + str(start) + " " + str(end) + " " + str(count) + "\n")
            
        t.close()                    
    print("###### Creating output file" + " ######")
    input_dir = str(input_dir)
    distance_param = str(distance_param)
    
    stream = os.popen(f"./single_linkage {input_dir} {distance_param}")
    output = stream.read()
    
    print("###### Output ######")
    print("###### successfully done C++ script " + "######")
    return output
         
def generate_input(in_slc_dir):
    """
    Parameters
    ----------            
    in_slc_dir : string
        directory toward a folder that contains input and output of single linkage clustering script (C++ script).
        
    Returns
    -------    
    in_templ : string
        input directory template of the single linkage clustering script. 
        e.g. ../numPolyA_inputSLC_"

    temp_file : string
        output directory of the single linkage clustering script.
        e.g. ../numPolyA_slc_output_.txt
        
    """    
    in_templ = in_slc_dir + "/numPolyA_inputSLC_"
    temp_dir = in_slc_dir + "/numPolyA_slc_output_"
   
    temp_file = temp_dir + ".txt"  
    return in_templ, temp_file

def get_args():        
    parser = argparse.ArgumentParser(description="get number of polyA sites")

    parser.add_argument('--bam', dest = 'bam',
                        required = True,
                        help = 'bam file containing polyA reads')
        
    parser.add_argument('--slc_distance', type = int, dest = 'slc_distance',
                        required = True,
                        help = 'single linkage cluster dsitance parameter')

    parser.add_argument('--num_polyA_in_slc', dest = 'num_polyA_in_slc',
                        required = True,
                        help = 'directory towards num_polyA_in_slc folder')  
    
    parser.add_argument('--csv_out_name', dest = 'csv_out_name',
                        required = True,
                        help = 'output number of polyA sites csv file name')

    parser.add_argument('--barchart_out_name', dest = 'barchart_out_name',
                        required = True,
                        help = 'file name of bar chart of distribution of PAS')
    
    parser.add_argument('--cluster_threshold', dest = 'cluster_threshold',
                        required = True,
                        help = 'a threshold of how many reads should at least support this cluster in order to consider this cluster as a polyA sites.')
    
    args = parser.parse_args()
    
    bam_dir = args.bam
    bam = pysam.AlignmentFile(bam_dir, "rb")  
    
    slc_distance = args.slc_distance
    num_polyA_in_slc = args.num_polyA_in_slc
    csv_out_name = args.csv_out_name
    barchart_out_name = args.barchart_out_name
    
    cluster_threshold = int(args.cluster_threshold)
    
    return bam, slc_distance, num_polyA_in_slc, csv_out_name, barchart_out_name, cluster_threshold

def run_process():

    bam, slc_distance, num_polyA_in_slc, csv_out_name, barchart_out_name, cluster_threshold = get_args()
    print('successfully got arguments')
    
    in_templ, temp_file = generate_input(num_polyA_in_slc)
    print("successfully initialized input" )

    slc_output = make_input_slc(in_templ, bam, slc_distance)
    print("successfully generated output of slc")
    
    # temp_file contains output of single linkage clustering
    write_temp(temp_file, slc_output)
    print("successfully saved slc_output")                                 

    clusters_read_ends = make_cluster(temp_file)
    print("successfully made dictionary" )
    
    num_polyA_sites, GX_distribution_dictionary = get_num_polyA_alter(clusters_read_ends, cluster_threshold)
    print("successfully got number of polyA sites")

    # e.g. 10X_P4_7
    sample_name = '_'.join(csv_out_name.split('_')[0:3])
    num_polyA_data = [sample_name, num_polyA_sites]
    
    write_out(num_polyA_data, csv_out_name)
    print('successfully saved the result')
    
    plot_histogram(GX_distribution_dictionary, barchart_out_name)
    print("successfully drew the plot")
    
if __name__ == "__main__":
    run_process()
    print("success")